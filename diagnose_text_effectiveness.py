# diagnose_text_effectiveness.py
import torch
import sys
sys.path.append('/root/autodl-tmp/CoreDiff-main')

from text_conditioned_dataset import TextConditionedCTDataset

print("="*70)
print("ğŸ” è¯Šæ–­æ–‡æœ¬æ¡ä»¶çš„æœ‰æ•ˆæ€§")
print("="*70)

# 1. æ£€æŸ¥ embedding åŒºåˆ†åº¦
dataset_25 = TextConditionedCTDataset(
    dataset='mayo_2016', mode='train', test_id=9,
    dose=25, context=True, use_text=True
)
dataset_50 = TextConditionedCTDataset(
    dataset='mayo_2016', mode='train', test_id=9,
    dose=50, context=True, use_text=True
)

sample_25 = dataset_25[0]
sample_50 = dataset_50[0]

emb_25 = torch.from_numpy(sample_25['text_embedding'])
emb_50 = torch.from_numpy(sample_50['text_embedding'])

# è®¡ç®—åŒºåˆ†åº¦
l2_dist = torch.norm(emb_25 - emb_50).item()
cos_sim = torch.nn.functional.cosine_similarity(
    emb_25.unsqueeze(0), emb_50.unsqueeze(0)
).item()

print(f"\nğŸ“Š Text Embedding åŒºåˆ†åº¦:")
print(f"  25% embedding norm: {emb_25.norm().item():.4f}")
print(f"  50% embedding norm: {emb_50.norm().item():.4f}")
print(f"  L2 distance: {l2_dist:.4f}")
print(f"  Cosine similarity: {cos_sim:.4f}")

if l2_dist < 0.5:
    print(f"\nâŒ åŒºåˆ†åº¦è¿‡ä½ï¼L2è·ç¦» {l2_dist:.4f} < 0.5")
    print("   â†’ æ–‡æœ¬æ¡ä»¶æ— æ³•æœ‰æ•ˆåŒºåˆ†ä¸åŒå‰‚é‡")
elif cos_sim > 0.98:
    print(f"\nâš ï¸  æ–¹å‘è¿‡äºç›¸ä¼¼ï¼ä½™å¼¦ç›¸ä¼¼åº¦ {cos_sim:.4f} > 0.98")
    print("   â†’ æ–‡æœ¬æ¡ä»¶æ–¹å‘æ€§ä¸å¤Ÿ")
else:
    print(f"\nâœ… åŒºåˆ†åº¦åˆæ ¼")

print(f"\nğŸ“ æ–‡æœ¬æè¿°:")
print(f"  25%: {sample_25['description'][:100]}...")
print(f"  50%: {sample_50['description'][:100]}...")

# 2. æ£€æŸ¥æ¨¡å‹ä¸­æ–‡æœ¬æ¡ä»¶çš„å®é™…å½±å“
print(f"\n" + "="*70)
print("ğŸ” æ£€æŸ¥æ¨¡å‹ä¸­æ–‡æœ¬æ¡ä»¶çš„å½±å“")
print("="*70)

from models.corediff.corediff_wrapper import UNet

model = UNet(in_channels=3, text_emb_dim=256).cuda()

# æ¨¡æ‹Ÿè¾“å…¥
x = torch.randn(2, 3, 512, 512).cuda()
t = torch.tensor([5, 5]).cuda()
x_adjust = torch.randn(2, 2, 512, 512).cuda()

# å¯¹æ¯”æœ‰æ— æ–‡æœ¬æ¡ä»¶çš„è¾“å‡º
with torch.no_grad():
    out_no_text, _ = model(x, t, x_adjust, adjust=False, text_emb=None)
    out_with_text_25, _ = model(x, t, x_adjust, adjust=False, text_emb=emb_25.unsqueeze(0).cuda())
    out_with_text_50, _ = model(x, t, x_adjust, adjust=False, text_emb=emb_50.unsqueeze(0).cuda())

diff_25 = (out_with_text_25 - out_no_text).abs().mean().item()
diff_50 = (out_with_text_50 - out_no_text).abs().mean().item()
diff_25_50 = (out_with_text_25 - out_with_text_50).abs().mean().item()

print(f"\nè¾“å‡ºå·®å¼‚:")
print(f"  æ— æ–‡æœ¬ vs 25%æ–‡æœ¬: {diff_25:.6f}")
print(f"  æ— æ–‡æœ¬ vs 50%æ–‡æœ¬: {diff_50:.6f}")
print(f"  25%æ–‡æœ¬ vs 50%æ–‡æœ¬: {diff_25_50:.6f}")

if diff_25 < 0.001 and diff_50 < 0.001:
    print(f"\nâŒ æ–‡æœ¬æ¡ä»¶å‡ ä¹ä¸å½±å“è¾“å‡ºï¼")
    print(f"   â†’ éœ€è¦å¢å¼ºæ–‡æœ¬æ³¨å…¥æœºåˆ¶")
elif diff_25_50 < 0.0001:
    print(f"\nâŒ ä¸åŒå‰‚é‡çš„æ–‡æœ¬æ¡ä»¶äº§ç”Ÿç›¸åŒè¾“å‡ºï¼")
    print(f"   â†’ æ–‡æœ¬embeddingåŒºåˆ†åº¦ä¸å¤Ÿ æˆ– æ³¨å…¥æ–¹å¼æœ‰é—®é¢˜")
else:
    print(f"\nâœ… æ–‡æœ¬æ¡ä»¶æ­£å¸¸å·¥ä½œ")

print(f"\n" + "="*70)