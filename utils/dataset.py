import os
import os.path as osp
from glob import glob
from torch.utils.data import Dataset
import numpy as np
from functools import partial


class CTDataset(Dataset):
    def __init__(self, dataset, mode, test_id=9, dose=5, context=True):
        self.mode = mode
        self.context = context
        print(f"ğŸ“Š Initializing dataset: {dataset}, mode: {mode}, dose: {dose}")

        if dataset in ['mayo_2016_sim', 'mayo_2016']:
            if dataset == 'mayo_2016_sim':
                data_root = './data_preprocess/gen_data/mayo_2016_sim_npy'
            elif dataset == 'mayo_2016':
                data_root = '/root/autodl-tmp/CoreDiff-main/data/Mayo16_SM_dose25_and_dose50'

            # ç—…äººåˆ—è¡¨
            patient_ids = [67, 96, 109, 143, 192, 286, 291, 310, 333, 506]
            if mode == 'train':
                patient_ids.pop(test_id)
            elif mode == 'test':
                patient_ids = patient_ids[test_id:test_id + 1]

            # === è§£æ dose å‚æ•° ===
            if isinstance(dose, (list, tuple)):
                dose_list = dose
            elif isinstance(dose, str):
                dose_list = [int(d.strip()) for d in dose.split(',')]
            else:
                dose_list = [dose]
            
            print(f"âœ… Training with dose levels: {dose_list}")

            # === æ ¸å¿ƒä¿®å¤: ä¸ºæ¯ä¸ªç—…äººå•ç‹¬å¤„ç†,ä¿æŒæ—¶åºè¿ç»­æ€§ ===
            patient_input_lists = []
            patient_target_lists = []
            
            for patient_id in patient_ids:
                # åŠ è½½è¯¥ç—…äººçš„æ‰€æœ‰targetæ–‡ä»¶(ä¸åˆ†dose,targetæ˜¯å›ºå®šçš„)
                target_files = sorted(glob(osp.join(data_root, f'L{patient_id:03d}_*_target.npy')))
                
                # å¯¹æ¯ä¸ªdose levelåˆ†åˆ«å¤„ç†
                for d in dose_list:
                    # åŠ è½½è¯¥ç—…äººåœ¨è¯¥doseä¸‹çš„æ‰€æœ‰è¾“å…¥æ–‡ä»¶
                    input_files = sorted(glob(osp.join(data_root, f'L{patient_id:03d}_*_dose{d}.npy')))
                    
                    # ç¡®ä¿inputå’Œtargetæ•°é‡åŒ¹é…
                    if len(input_files) != len(target_files):
                        print(f"âš ï¸ Patient {patient_id}, dose {d}: input={len(input_files)}, target={len(target_files)}")
                    
                    # å¦‚æœä½¿ç”¨context,æ„å»ºä¸‰è”è¾“å…¥
                    if context:
                        # éœ€è¦å»æ‰é¦–å°¾,å› ä¸ºé¦–å°¾æ— æ³•æ„æˆä¸‰è”
                        if len(input_files) > 2:
                            for i in range(1, len(input_files) - 1):
                                # æ„å»ºä¸‰è”: [i-1, i, i+1]
                                triple_path = f"{input_files[i-1]}~{input_files[i]}~{input_files[i+1]}"
                                patient_input_lists.append(triple_path)
                                patient_target_lists.append(target_files[i])
                    else:
                        # ä¸ä½¿ç”¨context,ç›´æ¥ä½¿ç”¨å•å¸§(å»æ‰é¦–å°¾)
                        if len(input_files) > 2:
                            for i in range(1, len(input_files) - 1):
                                patient_input_lists.append(input_files[i])
                                patient_target_lists.append(target_files[i])

            self.input = patient_input_lists
            self.target = patient_target_lists
            
            print(f"âœ… Loaded from: {data_root}")
            print(f"âœ… Mixed doses: {dose_list}")
            print(f"âœ… Total inputs: {len(self.input)}, Total targets: {len(self.target)}")
            
            # âœ… æ£€æŸ¥æ•°é‡æ˜¯å¦åŒ¹é…
            if len(self.input) != len(self.target):
                print(f"âŒ ERROR: Input count ({len(self.input)}) != Target count ({len(self.target)})")
                raise ValueError("Input and target counts must match!")

        # å…¶ä»–æ•°æ®é›†ï¼ˆåŸæ ·ä¿ç•™ï¼‰
        elif dataset == 'mayo_2020':
            data_root = './data_preprocess/gen_data/mayo_2020_npy'
            if dose == 10:
                patient_ids = ['C052', 'C232', 'C016', 'C120', 'C050']
            elif dose == 25:
                patient_ids = ['L077', 'L056', 'L186', 'L006', 'L148']

            patient_lists = []
            for id in patient_ids:
                patient_list = sorted(glob(osp.join(data_root, (id + '_target_' + '*_img.npy'))))
                patient_lists += patient_list[1:len(patient_list) - 1]
            base_target = patient_lists

            patient_lists = []
            for id in patient_ids:
                patient_list = sorted(glob(osp.join(data_root, (id + '_{}_'.format(dose) + '*_img.npy'))))
                if context:
                    cat_patient_list = []
                    for i in range(1, len(patient_list) - 1):
                        patient_path = ''
                        for j in range(-1, 2):
                            patient_path = patient_path + '~' + patient_list[i + j]
                        cat_patient_list.append(patient_path)
                    patient_lists += cat_patient_list
                else:
                    patient_list = patient_list[1:len(patient_list) - 1]
                    patient_lists += patient_list
            base_input = patient_lists
            
            self.input = base_input
            self.target = base_target
            print(f"âœ… Inputs: {len(self.input)}, Targets: {len(self.target)}")

    def __getitem__(self, index):
        input, target = self.input[index], self.target[index]
        if self.context:
            input = input.split('~')
            inputs = []
            for i in range(len(input)):  # ä¿®æ”¹: ä»0å¼€å§‹,è€Œä¸æ˜¯ä»1å¼€å§‹
                inputs.append(np.load(input[i])[np.newaxis, ...].astype(np.float32))
            input = np.concatenate(inputs, axis=0)  # (3,512,512)
        else:
            input = np.load(input)[np.newaxis, ...].astype(np.float32)
        target = np.load(target)[np.newaxis, ...].astype(np.float32)
        input = self.normalize_(input)
        target = self.normalize_(target)
        return input, target

    def __len__(self):
        return len(self.target)

    def normalize_(self, img, MIN_B=-1024, MAX_B=3072):
        img = img - 1024
        img[img < MIN_B] = MIN_B
        img[img > MAX_B] = MAX_B
        img = (img - MIN_B) / (MAX_B - MIN_B)
        return img


# ä¿ç•™åŸæ¥çš„ dict ä½œä¸ºåå¤‡
dataset_dict = {
    'train': partial(CTDataset, dataset='mayo_2016', mode='train', test_id=9, dose=25, context=True),
    'mayo_2016_sim': partial(CTDataset, dataset='mayo_2016_sim', mode='test', test_id=9, dose=5, context=True),
    'mayo_2016': partial(CTDataset, dataset='mayo_2016', mode='test', test_id=9, dose=25, context=True),
}