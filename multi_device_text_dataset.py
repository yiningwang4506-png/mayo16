"""
Multi-Device Text-Conditioned CT Dataset
æ”¯æŒå¤šè®¾å¤‡ã€å¤šå‰‚é‡çš„æ–‡æœ¬æ¡ä»¶æ•°æ®é›†
"""
import os
import os.path as osp
from glob import glob
from torch.utils.data import Dataset
import numpy as np
import torch
from functools import partial


# ============================================================
# æ–‡æœ¬æè¿°ç”Ÿæˆå™¨
# ============================================================
class MultiDeviceTextGenerator:
    """
    æ ¹æ®è®¾å¤‡å’Œå‰‚é‡ç”ŸæˆåŒ»å­¦æ–‡æœ¬æè¿°
    """
    
    # è®¾å¤‡æè¿°
    DEVICE_DESCRIPTIONS = {
        'LZU_PH': 'Philips scanner',
        'ZJU_GE': 'GE scanner', 
        'ZJU_UI': 'United Imaging scanner',
    }
    
    # å‰‚é‡æè¿°
    DOSE_DESCRIPTIONS = {
        10: '10% ultra-low-dose with high noise level',
        25: '25% low-dose with moderate noise level',
        50: '50% reduced-dose with mild noise level',
        100: 'full-dose with standard noise level',
    }
    
    @staticmethod
    def generate_description(device, dose):
        """
        ç”Ÿæˆæ–‡æœ¬æè¿°
        
        Args:
            device: 'LZU_PH', 'ZJU_GE', æˆ– 'ZJU_UI'
            dose: 10 æˆ– 25
            
        Returns:
            str: æ–‡æœ¬æè¿°
        """
        device_desc = MultiDeviceTextGenerator.DEVICE_DESCRIPTIONS.get(
            device, f'{device} scanner'
        )
        dose_desc = MultiDeviceTextGenerator.DOSE_DESCRIPTIONS.get(
            dose, f'{dose}% dose'
        )
        
        description = (
            f"This CT scan was acquired using a {device_desc} "
            f"with {dose_desc}."
        )
        
        return description


# ============================================================
# æ–‡æœ¬ç¼–ç å™¨ï¼ˆä½¿ç”¨ PubMed-BERTï¼‰
# ============================================================
class TextEncoder:
    """
    ä½¿ç”¨ PubMed-BERT ç¼–ç æ–‡æœ¬
    """
    
    def __init__(self, 
                 model_name='microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext',
                 output_dim=256,
                 cache_dir='./pretrained_models'):
        
        from transformers import AutoTokenizer, AutoModel
        import os
        
        # è®¾ç½®ç¦»çº¿æ¨¡å¼ï¼ˆå¦‚æœå·²ä¸‹è½½ï¼‰
        os.environ['TRANSFORMERS_OFFLINE'] = '1'
        os.environ['HF_HUB_OFFLINE'] = '1'
        
        print(f"ğŸ”„ Loading text encoder: {model_name}")
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name, 
                cache_dir=cache_dir,
                local_files_only=True
            )
            self.bert = AutoModel.from_pretrained(
                model_name,
                cache_dir=cache_dir,
                local_files_only=True
            )
            print("âœ… Text encoder loaded from local cache")
        except Exception as e:
            print(f"âš ï¸ Local cache not found, downloading...")
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name, 
                cache_dir=cache_dir,
                local_files_only=False
            )
            self.bert = AutoModel.from_pretrained(
                model_name,
                cache_dir=cache_dir,
                local_files_only=False
            )
            print("âœ… Text encoder downloaded and loaded")
        
        self.bert.eval()
        for param in self.bert.parameters():
            param.requires_grad = False
        
        # æŠ•å½±å±‚
        bert_dim = self.bert.config.hidden_size
        self.projection = torch.nn.Sequential(
            torch.nn.Linear(bert_dim, output_dim * 2),
            torch.nn.GELU(),
            torch.nn.Linear(output_dim * 2, output_dim),
        )
        
        self.output_dim = output_dim
        self._cache = {}  # ç¼“å­˜ç¼–ç ç»“æœ
        
    def encode(self, text):
        """ç¼–ç å•ä¸ªæ–‡æœ¬"""
        if text in self._cache:
            return self._cache[text]
        
        with torch.no_grad():
            inputs = self.tokenizer(
                text,
                return_tensors='pt',
                padding=True,
                truncation=True,
                max_length=128
            )
            
            outputs = self.bert(**inputs)
            cls_emb = outputs.last_hidden_state[:, 0, :]  # [1, 768]
            text_emb = self.projection(cls_emb)  # [1, 256]
            text_emb = text_emb.squeeze(0).numpy()  # [256]
        
        self._cache[text] = text_emb
        return text_emb


# ============================================================
# ç®€åŒ–ç‰ˆæ–‡æœ¬ç¼–ç å™¨ï¼ˆä¸éœ€è¦ BERTï¼Œç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
# ============================================================
class SimpleTextEncoder:
    """
    ç®€åŒ–ç‰ˆæ–‡æœ¬ç¼–ç å™¨
    ç›´æ¥ç”¨ one-hot ç¼–ç è®¾å¤‡å’Œå‰‚é‡
    """
    
    def __init__(self, output_dim=256):
        self.output_dim = output_dim
        
        # è®¾å¤‡ç¼–ç  (3ç§)
        self.device_map = {'LZU_PH': 0, 'ZJU_GE': 1, 'ZJU_UI': 2}
        
        # å‰‚é‡ç¼–ç  (2ç§)
        self.dose_map = {10: 0, 25: 1}
        
        # åˆ›å»ºå›ºå®šçš„ embedding
        np.random.seed(42)
        self.device_embeddings = np.random.randn(3, output_dim // 2).astype(np.float32)
        self.dose_embeddings = np.random.randn(2, output_dim // 2).astype(np.float32)
        
        # å½’ä¸€åŒ–
        self.device_embeddings /= np.linalg.norm(self.device_embeddings, axis=1, keepdims=True)
        self.dose_embeddings /= np.linalg.norm(self.dose_embeddings, axis=1, keepdims=True)
        
    def encode(self, device, dose):
        """
        ç¼–ç è®¾å¤‡å’Œå‰‚é‡
        
        Returns:
            np.ndarray: [output_dim]
        """
        device_idx = self.device_map.get(device, 0)
        dose_idx = self.dose_map.get(dose, 0)
        
        device_emb = self.device_embeddings[device_idx]
        dose_emb = self.dose_embeddings[dose_idx]
        
        # æ‹¼æ¥
        text_emb = np.concatenate([device_emb, dose_emb])
        
        return text_emb


# ============================================================
# å¤šè®¾å¤‡æ–‡æœ¬æ¡ä»¶æ•°æ®é›†
# ============================================================
class MultiDeviceTextConditionedDataset(Dataset):
    """
    å¤šè®¾å¤‡å¤šå‰‚é‡æ–‡æœ¬æ¡ä»¶æ•°æ®é›†
    """
    
    def __init__(self, 
                 data_root='./data',
                 mode='train',
                 devices=None,
                 doses=None,
                 num_test_patients=4,
                 context=True,
                 use_bert=True,  # æ˜¯å¦ä½¿ç”¨ BERT ç¼–ç 
                 text_emb_dim=256):
        
        self.mode = mode
        self.context = context
        self.data_root = data_root
        self.use_bert = use_bert
        
        # é»˜è®¤ä½¿ç”¨æ‰€æœ‰è®¾å¤‡å’Œå‰‚é‡
        if devices is None:
            devices = ['LZU_PH', 'ZJU_GE', 'ZJU_UI']
        if doses is None:
            doses = [10, 25]
        
        print(f"{'='*60}")
        print(f"ğŸ“Š MultiDeviceTextConditionedDataset åˆå§‹åŒ–")
        print(f"{'='*60}")
        print(f"  Mode: {mode}")
        print(f"  Devices: {devices}")
        print(f"  Doses: {doses}")
        print(f"  Context: {context}")
        print(f"  Use BERT: {use_bert}")
        
        # åˆå§‹åŒ–æ–‡æœ¬ç¼–ç å™¨
        if use_bert:
            print("ğŸ”„ Initializing BERT text encoder...")
            self.text_encoder = TextEncoder(output_dim=text_emb_dim)
        else:
            print("ğŸ”„ Using simple text encoder...")
            self.text_encoder = SimpleTextEncoder(output_dim=text_emb_dim)
        
        self.text_generator = MultiDeviceTextGenerator()
        
        self.input_files = []
        self.target_files = []
        self.metadata = []
        
        # éå†æ¯ä¸ªè®¾å¤‡å’Œå‰‚é‡
        for device in devices:
            for dose in doses:
                dir_name = f"{device}_dose{dose}"
                data_dir = osp.join(data_root, dir_name, dir_name)
                
                if not osp.exists(data_dir):
                    print(f"  âš ï¸ ç›®å½•ä¸å­˜åœ¨: {data_dir}")
                    continue
                
                all_files = sorted(glob(osp.join(data_dir, f"*_dose{dose}.npy")))
                if not all_files:
                    continue
                
                patient_ids = sorted(list(set([
                    osp.basename(f).split('_')[0] for f in all_files
                ])))
                
                # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•
                test_pids = patient_ids[-num_test_patients:]
                train_pids = patient_ids[:-num_test_patients]
                
                if mode == 'train':
                    selected_pids = train_pids
                else:
                    selected_pids = test_pids
                
                for pid in selected_pids:
                    patient_inputs = sorted(glob(
                        osp.join(data_dir, f"{pid}_*_dose{dose}.npy")
                    ))
                    patient_targets = sorted(glob(
                        osp.join(data_dir, f"{pid}_*_target.npy")
                    ))
                    
                    if len(patient_inputs) != len(patient_targets):
                        continue
                    
                    if len(patient_inputs) < 3:
                        continue
                    
                    if context:
                        for i in range(1, len(patient_inputs) - 1):
                            triple = f"{patient_inputs[i-1]}~{patient_inputs[i]}~{patient_inputs[i+1]}"
                            self.input_files.append(triple)
                            self.target_files.append(patient_targets[i])
                            self.metadata.append({
                                'device': device,
                                'dose': dose,
                                'patient': pid,
                                'slice': i
                            })
                    else:
                        for i in range(1, len(patient_inputs) - 1):
                            self.input_files.append(patient_inputs[i])
                            self.target_files.append(patient_targets[i])
                            self.metadata.append({
                                'device': device,
                                'dose': dose,
                                'patient': pid,
                                'slice': i
                            })
                
                count = len([m for m in self.metadata 
                           if m['device'] == device and m['dose'] == dose])
                print(f"  âœ… {dir_name}: {len(selected_pids)} patients, {count} samples")
        
        print(f"{'='*60}")
        print(f"ğŸ“Š æ€»è®¡: {len(self.input_files)} æ ·æœ¬")
        print(f"{'='*60}")
        
        # é¢„è®¡ç®—æ‰€æœ‰æ–‡æœ¬ embeddingï¼ˆåŠ é€Ÿè®­ç»ƒï¼‰
        print("ğŸ”„ Pre-computing text embeddings...")
        self._precompute_text_embeddings()
        print("âœ… Text embeddings ready!")
    
    def _precompute_text_embeddings(self):
        """é¢„è®¡ç®—æ‰€æœ‰è®¾å¤‡-å‰‚é‡ç»„åˆçš„æ–‡æœ¬ embedding"""
        self.text_embeddings = {}
        
        devices = set(m['device'] for m in self.metadata)
        doses = set(m['dose'] for m in self.metadata)
        
        for device in devices:
            for dose in doses:
                if self.use_bert:
                    desc = self.text_generator.generate_description(device, dose)
                    emb = self.text_encoder.encode(desc)
                else:
                    emb = self.text_encoder.encode(device, dose)
                
                key = f"{device}_{dose}"
                self.text_embeddings[key] = emb
                print(f"    {key}: {emb.shape}")
    
    def __getitem__(self, index):
        input_path = self.input_files[index]
        target_path = self.target_files[index]
        meta = self.metadata[index]
        
        # åŠ è½½å›¾åƒ
        if self.context:
            paths = input_path.split('~')
            imgs = [np.load(p)[np.newaxis, ...].astype(np.float32) for p in paths]
            input_img = np.concatenate(imgs, axis=0)
        else:
            input_img = np.load(input_path)[np.newaxis, ...].astype(np.float32)
        
        target_img = np.load(target_path)[np.newaxis, ...].astype(np.float32)
        
        # å½’ä¸€åŒ–
        input_img = self.normalize_(input_img)
        target_img = self.normalize_(target_img)
        
        # è·å–æ–‡æœ¬ embedding
        key = f"{meta['device']}_{meta['dose']}"
        text_emb = self.text_embeddings[key]
        
        return {
            'input': input_img.astype(np.float32),
            'target': target_img.astype(np.float32),
            'text_embedding': text_emb.astype(np.float32),
            'device': meta['device'],
            'dose': meta['dose'],
        }
    
    def __len__(self):
        return len(self.input_files)
    
    def normalize_(self, img, MIN_B=0, MAX_B=4000):
        img = np.clip(img, MIN_B, MAX_B)
        return img / MAX_B


# ============================================================
# æµ‹è¯•ä»£ç 
# ============================================================
if __name__ == '__main__':
    print("\n" + "="*70)
    print("ğŸ§ª æµ‹è¯• MultiDeviceTextConditionedDataset")
    print("="*70)
    
    # å…ˆç”¨ç®€å•ç¼–ç å™¨æµ‹è¯•ï¼ˆä¸éœ€è¦ BERTï¼‰
    print("\nã€æµ‹è¯•ç®€å•ç¼–ç å™¨ã€‘")
    dataset = MultiDeviceTextConditionedDataset(
        data_root='./data',
        mode='train',
        devices=['LZU_PH', 'ZJU_GE', 'ZJU_UI'],
        doses=[10, 25],
        num_test_patients=4,
        context=True,
        use_bert=False,  # ä¸ç”¨ BERTï¼Œå¿«é€Ÿæµ‹è¯•
        text_emb_dim=256
    )
    
    print(f"\næ•°æ®é›†å¤§å°: {len(dataset)}")
    
    # æµ‹è¯•æ ·æœ¬
    sample = dataset[0]
    print(f"\næ ·æœ¬å†…å®¹:")
    print(f"  Input shape: {sample['input'].shape}")
    print(f"  Target shape: {sample['target'].shape}")
    print(f"  Text embedding shape: {sample['text_embedding'].shape}")
    print(f"  Device: {sample['device']}")
    print(f"  Dose: {sample['dose']}%")
    
    # éªŒè¯ä¸åŒè®¾å¤‡/å‰‚é‡çš„ embedding ä¸åŒ
    print(f"\nã€éªŒè¯ embedding åŒºåˆ†åº¦ã€‘")
    emb_lzu_10 = dataset.text_embeddings['LZU_PH_10']
    emb_lzu_25 = dataset.text_embeddings['LZU_PH_25']
    emb_ge_10 = dataset.text_embeddings['ZJU_GE_10']
    
    def cosine_sim(a, b):
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
    
    print(f"  LZU_PH 10% vs 25%: {cosine_sim(emb_lzu_10, emb_lzu_25):.4f}")
    print(f"  LZU_PH 10% vs GE 10%: {cosine_sim(emb_lzu_10, emb_ge_10):.4f}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")