"""
Dose-Conditioned CT Dataset
æ”¯æŒ Dose Embedding çš„æ•°æ®é›†ï¼Œè¿”å›å‰‚é‡å€¼ç”¨äºæ¡ä»¶ç”Ÿæˆ
"""
import os
import os.path as osp
from glob import glob
from torch.utils.data import Dataset
import numpy as np
import torch
from functools import partial
import re


class DoseConditionedCTDataset(Dataset):
    """
    æ”¯æŒ Dose Embedding çš„CTæ•°æ®é›†
    è¿”å› dict æ ¼å¼ï¼ŒåŒ…å« dose å€¼
    """
    def __init__(self, dataset, mode, test_id=9, dose=5, context=True, use_text=True):
        """
        Args:
            dataset: æ•°æ®é›†åç§° ('mayo_2016', 'mayo_2016_sim', etc.)
            mode: 'train' æˆ– 'test'
            test_id: æµ‹è¯•é›†æ‚£è€…IDç´¢å¼•
            dose: å‰‚é‡å€¼ï¼Œæ”¯æŒ int, str, list
            context: æ˜¯å¦ä½¿ç”¨ä¸Šä¸‹æ–‡ (3å¸§)
            use_text: æ˜¯å¦å¯ç”¨ dose conditioning (ä¿æŒå‚æ•°åå…¼å®¹)
        """
        self.mode = mode
        self.context = context
        self.use_dose_condition = use_text  # å¤ç”¨ use_text å‚æ•°
        
        print(f"ğŸ“Š Initializing DoseConditioned dataset: {dataset}, mode: {mode}, dose: {dose}")
        print(f"ğŸ¯ Dose conditioning: {'ENABLED' if self.use_dose_condition else 'DISABLED'}")

        # === Mayo 2016 / Sim æ•°æ®é›†å¤„ç† ===
        if dataset in ['mayo_2016_sim', 'mayo_2016']:
            if dataset == 'mayo_2016_sim':
                data_root = './data_preprocess/gen_data/mayo_2016_sim_npy'
                self.dataset_name = 'mayo_2016_sim'
            else:
                data_root = '/root/autodl-tmp/CoreDiff-main/data/Mayo16_SM_dose25_and_dose50'
                self.dataset_name = 'mayo_2016'

            patient_ids = [67, 96, 109, 143, 192, 286, 291, 310, 333, 506]

            if mode == 'train':
                patient_ids.pop(test_id)
            else:
                patient_ids = patient_ids[test_id:test_id+1]

            # ç»Ÿä¸€è§£æ dose å‚æ•°
            if isinstance(dose, (list, tuple)):
                dose_list = dose
            elif isinstance(dose, str):
                dose_list = [int(v.strip()) for v in dose.split(',')]
            else:
                dose_list = [dose]

            print(f"âœ… Training with dose levels: {dose_list}")

            patient_input_lists = []
            patient_target_lists = []
            patient_dose_lists = []  # ğŸ”¥ è®°å½•æ¯ä¸ªæ ·æœ¬çš„ dose å€¼

            for pid in patient_ids:
                target_files = sorted(glob(osp.join(data_root, f"L{pid:03d}_*_target.npy")))

                for d in dose_list:
                    input_files = sorted(glob(osp.join(data_root, f"L{pid:03d}_*_dose{d}.npy")))

                    if len(input_files) != len(target_files):
                        print(f"âš ï¸ Mismatch: patient {pid}, dose {d} â†’ {len(input_files)} vs {len(target_files)}")

                    if context:
                        if len(input_files) > 2:
                            for i in range(1, len(input_files)-1):
                                triple = f"{input_files[i-1]}~{input_files[i]}~{input_files[i+1]}"
                                patient_input_lists.append(triple)
                                patient_target_lists.append(target_files[i])
                                patient_dose_lists.append(d)  # ğŸ”¥ è®°å½• dose
                    else:
                        if len(input_files) > 2:
                            for i in range(1, len(input_files)-1):
                                patient_input_lists.append(input_files[i])
                                patient_target_lists.append(target_files[i])
                                patient_dose_lists.append(d)  # ğŸ”¥ è®°å½• dose

            self.input = patient_input_lists
            self.target = patient_target_lists
            self.doses = patient_dose_lists  # ğŸ”¥ å­˜å‚¨ dose åˆ—è¡¨

            print(f"âœ… Loaded from: {data_root}")
            print(f"âœ… Mixed doses: {dose_list}")
            print(f"âœ… Total samples: {len(self.input)}")

            if len(self.input) != len(self.target):
                raise ValueError("Input/Target counts mismatch")

        # Mayo 2020
        elif dataset == 'mayo_2020':
            self.dataset_name = 'mayo_2020'
            data_root = './data_preprocess/gen_data/mayo_2020_npy'

            # ç»Ÿä¸€è§£æ dose å‚æ•°
            if isinstance(dose, (list, tuple)):
                dose_val = dose[0]  # mayo_2020 åªæ”¯æŒå•å‰‚é‡
            elif isinstance(dose, str):
                dose_val = int(dose.split(',')[0])
            else:
                dose_val = dose

            if dose_val == 10:
                patient_ids = ['C052', 'C232', 'C016', 'C120', 'C050']
            else:
                patient_ids = ['L077', 'L056', 'L186', 'L006', 'L148']

            base_target = []
            base_input = []
            base_doses = []

            for id in patient_ids:
                plist = sorted(glob(osp.join(data_root, id + '_target_*_img.npy')))
                base_target += plist[1:-1]

            for id in patient_ids:
                plist = sorted(glob(osp.join(data_root, id + f"_{dose_val}_" + '*_img.npy')))
                if context:
                    cat_list = []
                    for i in range(1, len(plist)-1):
                        triple = '~'.join([plist[i+j] for j in [-1,0,1]])
                        cat_list.append(triple)
                        base_doses.append(dose_val)
                    base_input += cat_list
                else:
                    base_input += plist[1:-1]
                    base_doses += [dose_val] * (len(plist) - 2)

            self.input = base_input
            self.target = base_target
            self.doses = base_doses

            print(f"âœ… Inputs: {len(self.input)}, Targets: {len(self.target)}")

    def __getitem__(self, index):
        input_path, target_path = self.input[index], self.target[index]
        dose_value = self.doses[index]  # ğŸ”¥ è·å– dose å€¼

        # === åŠ è½½å›¾åƒ ===
        if self.context:
            paths = input_path.split('~')
            imgs = [np.load(p)[np.newaxis, ...].astype(np.float32) for p in paths]
            input_img = np.concatenate(imgs, axis=0)  # (3,H,W)
        else:
            input_img = np.load(input_path)[np.newaxis, ...].astype(np.float32)

        target_img = np.load(target_path)[np.newaxis, ...].astype(np.float32)

        # normalize
        input_img = self.normalize_(input_img)
        target_img = self.normalize_(target_img)

        # ğŸ”¥ è¿”å› dict æ ¼å¼ï¼ŒåŒ…å« dose
        if self.use_dose_condition:
            return {
                'input': input_img.astype(np.float32),
                'target': target_img.astype(np.float32),
                'dose': dose_value,  # ğŸ”¥ int ç±»å‹
            }
        else:
            # å‘åå…¼å®¹ï¼šè¿”å› tuple
            return input_img, target_img

    def __len__(self):
        return len(self.target)

    def normalize_(self, img, MIN_B=-1024, MAX_B=3072):
        img = img - 1024
        img = np.clip(img, MIN_B, MAX_B)
        return (img - MIN_B) / (MAX_B - MIN_B)


# === ä¾¿æ·å‡½æ•° ===
def create_dose_conditioned_dataset(dataset='mayo_2016', mode='train',
                                    test_id=9, dose=25, context=True, use_text=True):
    return DoseConditionedCTDataset(
        dataset=dataset,
        mode=mode,
        test_id=test_id,
        dose=dose,
        context=context,
        use_text=use_text,
    )


# === dict wrapper (å…¼å®¹ basic_template.py) ===
dose_dataset_dict = {
    'train': partial(create_dose_conditioned_dataset,
                     dataset='mayo_2016', mode='train',
                     test_id=9, dose=[25, 50],
                     context=True, use_text=True),

    'test_25': partial(create_dose_conditioned_dataset,
                       dataset='mayo_2016', mode='test',
                       test_id=9, dose=25,
                       context=True, use_text=True),

    'test_50': partial(create_dose_conditioned_dataset,
                       dataset='mayo_2016', mode='test',
                       test_id=9, dose=50,
                       context=True, use_text=True),
}


# === æµ‹è¯• ===
if __name__ == '__main__':
    print("="*60)
    print("ğŸ§ª Testing DoseConditionedCTDataset")
    print("="*60)
    
    # æµ‹è¯•å¤šå‰‚é‡æ•°æ®é›†
    dataset = DoseConditionedCTDataset(
        dataset='mayo_2016',
        mode='train',
        test_id=9,
        dose=[25, 50],
        context=True,
        use_text=True
    )
    
    print(f"\nğŸ“Š Dataset size: {len(dataset)}")
    
    # è·å–å‡ ä¸ªæ ·æœ¬
    for i in [0, 100, len(dataset)-1]:
        if i < len(dataset):
            sample = dataset[i]
            print(f"\nSample {i}:")
            print(f"  Input shape: {sample['input'].shape}")
            print(f"  Target shape: {sample['target'].shape}")
            print(f"  Dose: {sample['dose']}%")
    
    # ç»Ÿè®¡ dose åˆ†å¸ƒ
    dose_counts = {}
    for i in range(min(1000, len(dataset))):
        d = dataset[i]['dose']
        dose_counts[d] = dose_counts.get(d, 0) + 1
    
    print(f"\nğŸ“ˆ Dose distribution (first 1000 samples):")
    for d, count in sorted(dose_counts.items()):
        print(f"  {d}%: {count} samples")
    
    print("\nâœ… Test passed!")
