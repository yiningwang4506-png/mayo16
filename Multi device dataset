"""
Multi-Device CT Dataset
æ”¯æŒå¤šè®¾å¤‡ã€å¤šå‰‚é‡æ··åˆè®­ç»ƒçš„æ•°æ®é›†
"""
import os
import os.path as osp
from glob import glob
from torch.utils.data import Dataset
import numpy as np
from functools import partial


class MultiDeviceDataset(Dataset):
    """
    å¤šè®¾å¤‡å¤šå‰‚é‡æ··åˆæ•°æ®é›†
    
    æ”¯æŒçš„æ•°æ®æº:
    - LZU_PH_dose10, LZU_PH_dose25
    - ZJU_GE_dose10, ZJU_GE_dose25
    - ZJU_UI_dose10, ZJU_UI_dose25
    """
    
    def __init__(self, 
                 data_root='./data',
                 mode='train',
                 devices=None,  # ['LZU_PH', 'ZJU_GE', 'ZJU_UI'] æˆ– None è¡¨ç¤ºå…¨éƒ¨
                 doses=None,    # [10, 25] æˆ– None è¡¨ç¤ºå…¨éƒ¨
                 test_patients=None,  # æµ‹è¯•é›†æ‚£è€…IDåˆ—è¡¨ï¼Œå¦‚ ['P001', 'P002']
                 num_test_patients=4,  # æ¯ä¸ªè®¾å¤‡ç”¨å¤šå°‘æ‚£è€…åšæµ‹è¯•
                 context=True):
        """
        Args:
            data_root: æ•°æ®æ ¹ç›®å½•
            mode: 'train' æˆ– 'test'
            devices: ä½¿ç”¨å“ªäº›è®¾å¤‡ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨
            doses: ä½¿ç”¨å“ªäº›å‰‚é‡ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨
            test_patients: æŒ‡å®šæµ‹è¯•æ‚£è€…ï¼ŒNoneåˆ™è‡ªåŠ¨é€‰æ‹©æ¯ä¸ªè®¾å¤‡æœ€åå‡ ä¸ª
            num_test_patients: æ¯ä¸ªè®¾å¤‡ç”¨äºæµ‹è¯•çš„æ‚£è€…æ•°é‡
            context: æ˜¯å¦ä½¿ç”¨3å¸§ä¸Šä¸‹æ–‡
        """
        self.mode = mode
        self.context = context
        self.data_root = data_root
        
        # é»˜è®¤ä½¿ç”¨æ‰€æœ‰è®¾å¤‡å’Œå‰‚é‡
        if devices is None:
            devices = ['LZU_PH', 'ZJU_GE', 'ZJU_UI']
        if doses is None:
            doses = [10, 25]
        
        print(f"{'='*60}")
        print(f"ğŸ“Š MultiDeviceDataset åˆå§‹åŒ–")
        print(f"{'='*60}")
        print(f"  Mode: {mode}")
        print(f"  Devices: {devices}")
        print(f"  Doses: {doses}")
        print(f"  Context: {context}")
        
        self.input_files = []
        self.target_files = []
        self.metadata = []  # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„å…ƒä¿¡æ¯
        
        # éå†æ¯ä¸ªè®¾å¤‡å’Œå‰‚é‡
        for device in devices:
            for dose in doses:
                # æ„å»ºç›®å½•è·¯å¾„: data/LZU_PH_dose10/LZU_PH_dose10/
                dir_name = f"{device}_dose{dose}"
                data_dir = osp.join(data_root, dir_name, dir_name)
                
                if not osp.exists(data_dir):
                    print(f"  âš ï¸ ç›®å½•ä¸å­˜åœ¨: {data_dir}")
                    continue
                
                # è·å–æ‰€æœ‰æ‚£è€…
                all_files = sorted(glob(osp.join(data_dir, f"*_dose{dose}.npy")))
                if not all_files:
                    print(f"  âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶: {data_dir}/*_dose{dose}.npy")
                    continue
                
                # æå–æ‚£è€…ID
                patient_ids = sorted(list(set([
                    osp.basename(f).split('_')[0] for f in all_files
                ])))
                
                # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•
                if test_patients is not None:
                    # ä½¿ç”¨æŒ‡å®šçš„æµ‹è¯•æ‚£è€…
                    test_pids = [p for p in test_patients if p in patient_ids]
                    train_pids = [p for p in patient_ids if p not in test_patients]
                else:
                    # è‡ªåŠ¨åˆ’åˆ†ï¼šæœ€å num_test_patients ä¸ªæ‚£è€…ç”¨äºæµ‹è¯•
                    test_pids = patient_ids[-num_test_patients:]
                    train_pids = patient_ids[:-num_test_patients]
                
                # é€‰æ‹©å½“å‰æ¨¡å¼çš„æ‚£è€…
                if mode == 'train':
                    selected_pids = train_pids
                else:
                    selected_pids = test_pids
                
                # ä¸ºæ¯ä¸ªæ‚£è€…åŠ è½½æ•°æ®
                for pid in selected_pids:
                    # è·å–è¯¥æ‚£è€…çš„æ‰€æœ‰slice
                    patient_inputs = sorted(glob(
                        osp.join(data_dir, f"{pid}_*_dose{dose}.npy")
                    ))
                    patient_targets = sorted(glob(
                        osp.join(data_dir, f"{pid}_*_target.npy")
                    ))
                    
                    if len(patient_inputs) != len(patient_targets):
                        print(f"  âš ï¸ æ•°é‡ä¸åŒ¹é…: {pid} in {dir_name}")
                        continue
                    
                    if len(patient_inputs) < 3:
                        print(f"  âš ï¸ Sliceå¤ªå°‘: {pid} in {dir_name}")
                        continue
                    
                    # æ„å»ºæ ·æœ¬ï¼ˆè·³è¿‡é¦–å°¾ä»¥æ”¯æŒcontextï¼‰
                    if context:
                        for i in range(1, len(patient_inputs) - 1):
                            # ä¸‰å¸§è¾“å…¥
                            triple = f"{patient_inputs[i-1]}~{patient_inputs[i]}~{patient_inputs[i+1]}"
                            self.input_files.append(triple)
                            self.target_files.append(patient_targets[i])
                            self.metadata.append({
                                'device': device,
                                'dose': dose,
                                'patient': pid,
                                'slice': i
                            })
                    else:
                        for i in range(1, len(patient_inputs) - 1):
                            self.input_files.append(patient_inputs[i])
                            self.target_files.append(patient_targets[i])
                            self.metadata.append({
                                'device': device,
                                'dose': dose,
                                'patient': pid,
                                'slice': i
                            })
                
                # æ‰“å°ç»Ÿè®¡
                count = len([m for m in self.metadata 
                           if m['device'] == device and m['dose'] == dose])
                print(f"  âœ… {dir_name}: {len(selected_pids)} patients, {count} samples")
        
        print(f"{'='*60}")
        print(f"ğŸ“Š æ€»è®¡: {len(self.input_files)} æ ·æœ¬")
        print(f"{'='*60}")
        
        # ç»Ÿè®¡å„è®¾å¤‡/å‰‚é‡çš„æ ·æœ¬æ•°
        self._print_statistics()
    
    def _print_statistics(self):
        """æ‰“å°æ•°æ®åˆ†å¸ƒç»Ÿè®¡"""
        if not self.metadata:
            return
        stats = {}
        for m in self.metadata:
            key = f"{m['device']}_dose{m['dose']}"
            stats[key] = stats.get(key, 0) + 1
        
        print("\nğŸ“ˆ æ ·æœ¬åˆ†å¸ƒ:")
        for key, count in sorted(stats.items()):
            pct = count / len(self.metadata) * 100
            print(f"  {key}: {count} ({pct:.1f}%)")
    
    def __getitem__(self, index):
        input_path = self.input_files[index]
        target_path = self.target_files[index]
        
        # åŠ è½½å›¾åƒ
        if self.context:
            paths = input_path.split('~')
            imgs = [np.load(p)[np.newaxis, ...].astype(np.float32) for p in paths]
            input_img = np.concatenate(imgs, axis=0)  # (3, H, W)
        else:
            input_img = np.load(input_path)[np.newaxis, ...].astype(np.float32)
        
        target_img = np.load(target_path)[np.newaxis, ...].astype(np.float32)
        
        # å½’ä¸€åŒ–
        input_img = self.normalize_(input_img)
        target_img = self.normalize_(target_img)
        
        return input_img, target_img
    
    def __len__(self):
        return len(self.input_files)
    
    def normalize_(self, img, MIN_B=-1024, MAX_B=3072):
        """CTå€¼å½’ä¸€åŒ–åˆ°[0,1]"""
        img = img - 1024
        img = np.clip(img, MIN_B, MAX_B)
        return (img - MIN_B) / (MAX_B - MIN_B)


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================

def create_multi_device_dataset(data_root='./data',
                                 mode='train',
                                 devices=None,
                                 doses=None,
                                 num_test_patients=4,
                                 context=True):
    """åˆ›å»ºå¤šè®¾å¤‡æ•°æ®é›†çš„ä¾¿æ·å‡½æ•°"""
    return MultiDeviceDataset(
        data_root=data_root,
        mode=mode,
        devices=devices,
        doses=doses,
        num_test_patients=num_test_patients,
        context=context
    )


# é¢„å®šä¹‰çš„æ•°æ®é›†é…ç½®
multi_device_dataset_dict = {
    'train': partial(create_multi_device_dataset,
                     data_root='./data',
                     mode='train',
                     devices=['LZU_PH', 'ZJU_GE', 'ZJU_UI'],
                     doses=[10, 25],
                     num_test_patients=4,
                     context=True),
    
    'test': partial(create_multi_device_dataset,
                    data_root='./data',
                    mode='test',
                    devices=['LZU_PH', 'ZJU_GE', 'ZJU_UI'],
                    doses=[10, 25],
                    num_test_patients=4,
                    context=True),
}


# ============================================================
# æµ‹è¯•ä»£ç 
# ============================================================

if __name__ == '__main__':
    print("\n" + "="*70)
    print("ğŸ§ª æµ‹è¯• MultiDeviceDataset")
    print("="*70)
    
    # æµ‹è¯•è®­ç»ƒé›†
    print("\nã€è®­ç»ƒé›†ã€‘")
    train_dataset = MultiDeviceDataset(
        data_root='./data',
        mode='train',
        devices=['LZU_PH', 'ZJU_GE', 'ZJU_UI'],
        doses=[10, 25],
        num_test_patients=4,
        context=True
    )
    
    print(f"\nè®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    
    # æµ‹è¯•æµ‹è¯•é›†
    print("\nã€æµ‹è¯•é›†ã€‘")
    test_dataset = MultiDeviceDataset(
        data_root='./data',
        mode='test',
        devices=['LZU_PH', 'ZJU_GE', 'ZJU_UI'],
        doses=[10, 25],
        num_test_patients=4,
        context=True
    )
    
    print(f"\næµ‹è¯•é›†å¤§å°: {len(test_dataset)}")
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    if len(train_dataset) > 0:
        print("\nã€æ•°æ®åŠ è½½æµ‹è¯•ã€‘")
        sample = train_dataset[0]
        print(f"  Input shape: {sample[0].shape}")
        print(f"  Target shape: {sample[1].shape}")
        print(f"  Input range: [{sample[0].min():.4f}, {sample[0].max():.4f}]")
        print(f"  Target range: [{sample[1].min():.4f}, {sample[1].max():.4f}]")
        
        # æ˜¾ç¤ºå…ƒä¿¡æ¯
        print(f"\n  æ ·æœ¬å…ƒä¿¡æ¯: {train_dataset.metadata[0]}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
    